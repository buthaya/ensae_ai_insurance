{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Hands-on - pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most famous library to manipulate data is `pandas`. It provides a large amount of functionalities similar to SAS (select, groupby, filter, etc.). \n",
    "\n",
    "The library is particularly well-suited for handling and manipulating structured data, such as CSV, Excel spreadsheets or SQL tables.\n",
    "\n",
    "`pandas` plays a crucial role in the entire data science workflow, from initial data exploration and cleaning to advanced data analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation and Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pandas\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of the library: we tag it as np to avoid us writting the full name each time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data structures in pandas\n",
    "\n",
    "\n",
    "Pandas provides two types of classes for handling data:\n",
    "\n",
    "* **Series**: a one-dimensional labeled array holding data of any type\n",
    "such as integers, strings, Python objects etc.\n",
    "\n",
    "* **DataFrame**: a two-dimensional data structure that holds data like a two-dimension array or a table with rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1: Object creation\n",
    "\n",
    "1. Creating a Series by passing a list of values, letting pandas create a default RangeIndex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 3, 5, np.nan, 6, 8]\n",
    "\n",
    "serie = # create a pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let's assume that the variable `data` is a list that contains our data.\n",
    "\n",
    "An observation corresponds to a dictionary that contains the name, type, atmosphere and rating of a restaurant.\n",
    "\n",
    "It is easy to transform this list into a dataframe using the 'DataFrame' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"name\": \"Little Pub\", \"type\" : \"Bar\", \"atmosphere\": 9, \"rating\": 7},\n",
    "     {\"name\": \"Le Corse\", \"type\" : \"Sandwicherie\", \"atmosphere\": 2, \"rating\": 8},\n",
    "     {\"name\": \"Café Caumartin\", \"type\" : \"Bar\", \"atmosphere\": 1}]\n",
    "\n",
    "df_restaurant = # create a pd.DataFrame\n",
    "\n",
    "df_restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurant.describe(include= ['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurant.describe(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays have one dtype for the entire array while pandas DataFrames have one dtype per column. When you call `DataFrame.to_numpy()`, pandas will find the NumPy dtype that can hold all of the dtypes in the DataFrame. If the common data type is object, `DataFrame.to_numpy()` will require copying data.\n",
    "\n",
    "`object` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurant.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurant.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Some basic operations\n",
    "\n",
    "* Getitem ([])\n",
    "* Selection by label .loc\n",
    "* Seletion by position .iloc\n",
    "* Boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getitem ([])\n",
    "df_restaurant['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection by label .loc\n",
    "df_restaurant.loc[:,'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seletion by position .iloc\n",
    "df_restaurant.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing\n",
    "df_restaurant[df_restaurant.atmosphere > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2: Titanic survival prediction\n",
    "\n",
    "Will Cukierski. (2012). Titanic - Machine Learning from Disaster. Kaggle. https://kaggle.com/competitions/titanic\n",
    "\n",
    "\n",
    "| **Column Name** | **Type** | Description                                                  |\n",
    "| --------------- | -------- | ------------------------------------------------------------ |\n",
    "| `PassengerId`   | int      | Id of the passenger in this dataset                          |\n",
    "| `Survived`      | int      | Boolean indicating whether or not the passenger survived the voyage (0 = No, 1 = Yes) |\n",
    "| `Pclass`        | int      | Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)                     |\n",
    "| `Name`          | string   | Name of the passenger                                        |\n",
    "| `Sex`           | string   | Sex of the passenger                                         |\n",
    "| `Age`           | float    | Age of the passenger in years                                |\n",
    "| `SibSp`         | int      | Number of siblings or spouses also aboard the Titanic        |\n",
    "| `Parch`         | int      | Number of parents or children also aboard the Titanic        |\n",
    "| `Ticket`        | string   | Ticket Number                                                |\n",
    "| `Fare`          | float    | Passenger fare (in USD)                                      |\n",
    "| `Cabin`         | string   | Cabin Number                                                 |\n",
    "| `Embarked`      | string   | Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading\n",
    "\n",
    "Load the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dataset/titanic/train.csv'\n",
    "titanic = # read the csv with pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get columns name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a column by its name and apply head method on result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema of dataframes is described with python numpy dtype object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the dtype of the a given column == np.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe only object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a concise summary of a DataFrame with pandas.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the average age for male versus female Titanic passengers?\n",
    "\n",
    "![https://pandas.pydata.org/docs/_images/06_groupby_select_detail.svg](https://pandas.pydata.org/docs/_images/06_groupby_select_detail.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the mean ticket fare price for each of the sex and cabin class combinations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the number of passengers in each of the cabin classes?\n",
    "\n",
    "![https://pandas.pydata.org/docs/_images/06_valuecounts.svg](https://pandas.pydata.org/docs/_images/06_valuecounts.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use value_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is a shortcut, as it is actually a groupby operation in combination with counting of the number of records within each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use groupby then count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a new feature extracting from existing (Add Computed Column)\n",
    "\n",
    "Extract Title feature using regular expressions. The RegEx pattern (\\w+\\.) matches the first word which ends with a dot character within Name feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_title(full_name: str):\n",
    "    match = re.search('(\\w+\\.)', full_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#use apply\n",
    "\n",
    "#use str.extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization\n",
    "\n",
    "Pandas has also some plot functionalities that can be used to have a quick overview of your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of Age per Sex with a pie plot\n",
    "\n",
    "\n",
    "# Set labels and title\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Age per Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age Distribution with a hist plot\n",
    "\n",
    "\n",
    "# Set labels and title\n",
    "# plt.title('Age Distribution')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fare Distribution with hist plot and bins=20\n",
    "\n",
    "\n",
    "# plt.title('Fare Distribution')\n",
    "# plt.xlabel('Fare')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of Age per Sex with a hist plot\n",
    "\n",
    "\n",
    "# Set labels and title\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Age per Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Survival Rate by Passenger Class\n",
    "\n",
    "\n",
    "# plt.title('Survival Rate by Passenger Class')\n",
    "# plt.xlabel('Passenger Class')\n",
    "# plt.ylabel('Survival Rate (%)')\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra - loading large dataset\n",
    "\n",
    "pandas provides data structures for in-memory analytics (RAM memory), which makes using pandas to analyze datasets that are larger than memory datasets somewhat tricky. Even datasets that are a sizable fraction of memory become unwieldy, as some pandas operations need to make intermediate copies.\n",
    "\n",
    "1. Load less data\n",
    "\n",
    "With `pandas.read_csv()`, you can specify usecols to limit the columns read into memory and userows to limit the rows read into memory. Not all file formats that can be read by pandas provide an option to read a subset of columns.\n",
    "\n",
    "2. Use efficient datatypes: [dtypes](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes)\n",
    "\n",
    "3. Use Chunking\n",
    "\n",
    "Some workloads can be achieved with chunking by splitting a large problem into a bunch of small problems.\n",
    "\n",
    "4. Use Dask\n",
    "\n",
    "pandas is just one library offering a DataFrame API. Because of its popularity, pandas’ API has become something of a standard that other libraries implement. The pandas documentation maintains a list of libraries implementing a DataFrame API in the ecosystem page.\n",
    "\n",
    "For example, [Dask](https://dask.org/), a parallel computing library, has [dask.dataframe](https://docs.dask.org/en/latest/dataframe.html), a pandas-like API for working with larger than memory datasets in parallel. Dask can use multiple threads or processes on a single machine, or a cluster of machines to process data in parallel.\n",
    "\n",
    "One major difference: the dask.dataframe API is lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parquet is a columnar storage file format that is commonly used in big data processing frameworks like Apache Spark and Apache Hadoop. It is designed to efficiently store and process large amounts of data by organizing data into columns rather than rows, which can lead to better compression and faster querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"../dataset/timeseries_wide.parquet\").info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only loads the columns we request\n",
    "columns = [\"id_0\", \"name_0\", \"x_0\", \"y_0\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use efficient datatypes\n",
    "\n",
    "titanic2 = titanic.copy()\n",
    "#pandas.Categorical\n",
    "#unsigned for small integer\n",
    "titanic2.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
